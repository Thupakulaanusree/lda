from sklearn.datasets import load_wine
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Load the Wine dataset
data = load_wine()
X = data.data
y = data.target

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train LDA model
lda = LDA()
lda.fit(X_train, y_train)

# Evaluate LDA model
y_pred_lda = lda.predict(X_test)
accuracy_lda = accuracy_score(y_test, y_pred_lda)
precision_lda = precision_score(y_test, y_pred_lda, average='weighted')
recall_lda = recall_score(y_test, y_pred_lda, average='weighted')
conf_matrix_lda = confusion_matrix(y_test, y_pred_lda)

# Train Logistic Regression model
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train, y_train)

# Evaluate Logistic Regression model
y_pred_log_reg = log_reg.predict(X_test)
accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)
precision_log_reg = precision_score(y_test, y_pred_log_reg, average='weighted')
recall_log_reg = recall_score(y_test, y_pred_log_reg, average='weighted')
conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)

# Print evaluation results
print("LDA Model - Accuracy:", accuracy_lda)
print("LDA Model - Precision:", precision_lda)
print("LDA Model - Recall:", recall_lda)
print("LDA Confusion Matrix:\n", conf_matrix_lda)

print("\nLogistic Regression - Accuracy:", accuracy_log_reg)
print("Logistic Regression - Precision:", precision_log_reg)
print("Logistic Regression - Recall:", recall_log_reg)
print("Logistic Regression Confusion Matrix:\n", conf_matrix_log_reg)

# Optional: Visualize Decision Boundaries
# Reduce to 2D using LDA
lda_2d = LDA(n_components=2)
X_train_2d = lda_2d.fit_transform(X_train, y_train)
X_test_2d = lda_2d.transform(X_test)

# Plotting decision boundaries for LDA in 2D
plt.figure(figsize=(10, 5))

# Scatter plot for LDA decision boundaries
plt.subplot(1, 2, 1)
sns.scatterplot(x=X_train_2d[:, 0], y=X_train_2d[:, 1], hue=y_train, palette='viridis', s=60, alpha=0.7)
plt.title("LDA - Decision Boundaries in 2D")

# Scatter plot for Logistic Regression decision boundaries in 2D
# Use the LDA-reduced 2D data for logistic regression for visualization
plt.subplot(1, 2, 2)
sns.scatterplot(x=X_train_2d[:, 0], y=X_train_2d[:, 1], hue=y_train, palette='viridis', s=60, alpha=0.7)
plt.title("Logistic Regression - Decision Boundaries in 2D")

plt.tight_layout()
plt.show()
